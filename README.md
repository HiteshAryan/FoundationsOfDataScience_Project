# FoundationsOfDataScience_Project

#ASSIGNMEMT-1
#Problem Statement:
#Bob and Lisa would like to find out the probability of getting head, μ, of a biased coin. They are excited to
get a probability distribution of μ but not just a point estimate. You will have to randomly generate a dataset
for this problem wherein the size of the dataset should be around 160 and μML ∉ (0.4,0.6). μML is maximum
likelihood estimator of the data that is being generated by you. As we know, 𝑜𝑠𝑡𝑒𝑟𝑖𝑜𝑟 ∝ 𝑙𝑖𝑘𝑒𝑙𝑖ℎ𝑜𝑜𝑑 ⨯
𝑝𝑟𝑖𝑜𝑟 , i.e. 𝑝(𝜇 | 𝐷, 𝑎, 𝑏) ∝ 𝑝(𝐷 | 𝜇) 𝑝(𝜇 | 𝑎, 𝑏) . Our goal is to find the distribution followed by the mean
of the coin tosses after observing the data points. As we know, coin tossing follows a Bernoulli distribution.
Its probability density function is given by 𝐵𝑒𝑟𝑛(𝑥 | 𝜇) = 𝜇
𝑥 (1 − 𝜇)
1−𝑥 where μ is the mean of the
Bernoulli distribution. Thus, for a dataset D of N points, we get the likelihood function as:
𝑝(𝐷 | 𝜇) = ∏𝑝(𝑥𝑛
| 𝜇)
𝑁
𝑛=1
= ∏𝜇
𝑥𝑛 (1 − 𝜇)
1−𝑥𝑛
𝑁
𝑛=1
We will take the prior to be a beta distribution. The PDF for a beta distribution is given by:
𝐵𝑒𝑡𝑎(𝜇| 𝑎, 𝑏) =
𝛤(𝑎 + 𝑏)
𝛤(𝑎)𝛤(𝑏)
𝜇
𝑎−1 (1 − 𝜇)
𝑏−1
where a and b are the parameters and Γ is the gamma function (The gamma function is available in the Scipy
library as scipy.special.gamma). Choose appropriate a and b such that the mean of the prior is 0.4. As
seen in class, we know how to find out the posterior distribution given prior distribution and likelihood
function. There are two approaches to find out the posterior distribution – one is to use all 160 data points
at one go and the other is to use each data point sequentially.


#ASSIGNMENT-2
#Problem Statement:
#Bob and Lisa would like to find out the probability of getting head, μ, of a biased coin. They are excited to
get a probability distribution of μ but not just a point estimate. You will have to randomly generate a dataset
for this problem wherein the size of the dataset should be around 160 and μML ∉ (0.4,0.6). μML is maximum
likelihood estimator of the data that is being generated by you. As we know, 𝑜𝑠𝑡𝑒𝑟𝑖𝑜𝑟 ∝ 𝑙𝑖𝑘𝑒𝑙𝑖ℎ𝑜𝑜𝑑 ⨯
𝑝𝑟𝑖𝑜𝑟 , i.e. 𝑝(𝜇 | 𝐷, 𝑎, 𝑏) ∝ 𝑝(𝐷 | 𝜇) 𝑝(𝜇 | 𝑎, 𝑏) . Our goal is to find the distribution followed by the mean
of the coin tosses after observing the data points. As we know, coin tossing follows a Bernoulli distribution.
Its probability density function is given by 𝐵𝑒𝑟𝑛(𝑥 | 𝜇) = 𝜇
𝑥 (1 − 𝜇)
1−𝑥 where μ is the mean of the
Bernoulli distribution. Thus, for a dataset D of N points, we get the likelihood function as:
𝑝(𝐷 | 𝜇) = ∏𝑝(𝑥𝑛
| 𝜇)
𝑁
𝑛=1
= ∏𝜇
𝑥𝑛 (1 − 𝜇)
1−𝑥𝑛
𝑁
𝑛=1
We will take the prior to be a beta distribution. The PDF for a beta distribution is given by:
𝐵𝑒𝑡𝑎(𝜇| 𝑎, 𝑏) =
𝛤(𝑎 + 𝑏)
𝛤(𝑎)𝛤(𝑏)
𝜇
𝑎−1 (1 − 𝜇)
𝑏−1
where a and b are the parameters and Γ is the gamma function (The gamma function is available in the Scipy
library as scipy.special.gamma). Choose appropriate a and b such that the mean of the prior is 0.4. As
seen in class, we know how to find out the posterior distribution given prior distribution and likelihood
function. There are two approaches to find out the posterior distribution – one is to use all 160 data points
at one go and the other is to use each data point sequentially.
